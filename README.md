# ğŸ”— OmniLink
### The Universal Neural Bridge

![OmniLink Banner](assets/banner.png)

![Status](https://img.shields.io/badge/Status-Beta-blue?style=for-the-badge) ![Platform](https://img.shields.io/badge/Platform-Linux%20%7C%20Windows-lightgrey?style=for-the-badge) ![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**Connect your Intelligence. Unify your Workflow.**

OmniLink is the vital synapse between your local AI backends and your development environment. It automatically synchronizes models from **Ollama**, **LM Studio**, and **Llama.cpp** directly into **OpenCode**, ensuring your coding assistant always has access to your latest local LLMs.

No more manual config editing. No more copy-pasting API keys. Just flow.

![OmniLink Showcase](assets/showcase.png)

---

## âœ¨ Features

*   **ğŸ”Œ Universal Adapter**: Scans multiple providers (Ollama, LM Studio, Llama.cpp) concurrently.
*   **ğŸ”„ Auto-Sync**: Detects new models and instantly updates your OpenCode config.
*   **ğŸ§¹ Smart Garbage Collection**: Automatically prunes dead links to models you've deleted.
*   **ğŸ“ Flexible Config Path**: Browse and select your own `opencode.json` location.
*   **ğŸ› ï¸ Auto-Create Config**: Creates the config file if it doesn't exist.
*   **ğŸ“Š Visual Telemetry**:
    *   **Linux**: Slick Terminal UI (TUI) with progress bars and status tables.
    *   **Windows**: Cyberpunk-themed GUI with neon aesthetics.
*   **ğŸ§  Context Awareness**: Remembers your server configurations so you only set them up once.

---

## ğŸ“¦ Download

### [â¬‡ï¸ Latest Release: OmniLink V0.1 BETA](https://github.com/mordang7/OmniLink/releases/tag/v0.1-beta)

| Platform | Download |
|----------|----------|
| ğŸ§ Linux | [OmniLink_V0.1_BETA_Linux.7z](https://github.com/mordang7/OmniLink/releases/download/v0.1-beta/OmniLink_V0.1_BETA_Linux.7z) |
| ğŸªŸ Windows | [OmniLink_V0.1_BETA_Windows.7z](https://github.com/mordang7/OmniLink/releases/download/v0.1-beta/OmniLink_V0.1_BETA_Windows.7z) |

---

## ğŸš€ Installation

### ğŸ§ Linux

1.  **Extract** the archive
2.  **Install**:
    ```bash
    chmod +x install.sh
    ./install.sh
    ```
3.  **Run**: Type `omnilink` in your terminal

### ğŸªŸ Windows

1.  **Extract** `OmniLink.exe` from the archive
2.  **Run**: Double-click `OmniLink.exe`

*No Python installation required - standalone executable!*

---

## ğŸ“‹ Requirements

*   **Backends**: Running instance of Ollama, LM Studio, or Llama.cpp
*   **Linux**: Python 3 (for installation only)
*   **Windows**: None (standalone .exe)

---

## ğŸ¤ Support the Project

If OmniLink streamlines your AI workflow, consider fueling the development!

[![Donate with PayPal](https://img.shields.io/badge/Donate-PayPal-blue.svg)](https://www.paypal.com/paypalme/GeekJohn)

---
*Connecting the dots in your local AI ecosystem.*
